Este capítulo aborda o planejamento, análise e execução do método proposto por este trabalho, a fim de verificar a viabilidade do projeto, bem como sua eficiência. O sistema computacional desenvolvido denomina-se \productname{} e tem seu código-fonte disponível em \url{https://github.com/rodrigost23/automailx}.

%==========================================================================
%
\section{Planejamento dos experimentos}\label{sec:result_planejamento}
%
%==========================================================================

O intuito desta avaliação experimental é verificar a capacidade do sistema \productname{} de classificar as ações do usuário a partir da leitura de sensores, e exibir um modelo virtual animado que demonstra os dados lidos e a detecção dos movimentos realizados. Neste sentido, foram definidas as seguintes questões de pesquisa:

\begin{enumerate}[label=\textbf{QP\arabic*:}, ref=QP\arabic*]
    \item O sistema \productname{} é capaz de replicar os movimentos realizados pelo usuário em um ambiente virtual?\label{qp:simula_movimentos}
    \item O sistema \productname{} pode prever as ações da prótese virtual em tempo real a partir dos dados dos sensores?\label{qp:previsao_sensores}
    \item O sistema \productname{} tem desempenho consistente independente do usuário?\label{qp:usuarios_diferentes}
    \item A acurácia da previsão de movimentos do sistema \productname{} é suficiente para garantir a sua confiabilidade?\label{qp:acuracia}
\end{enumerate}

Visando responder essas questões, foi definido um ambiente que consiste em um sistema de captura de movimentos acoplado ao \textit{software} simulador sendo executado em um computador.

% \subsection{Captura dos movimentos}\label{sec:result_captura}

O protótipo para captura de dados consiste em um módulo GY\=/\(521\) com um sensor MPU-\(6050\)~\cite{invensense:imu_mpu}, que contém um acelerômetro e um giroscópio, e um sensor flexível SparkFun de \(2{,}2\) polegadas~\cite{spectrasymbol:flex_sensor}, conectados em um Arduino Nano conforme o esquema da \autoref{fig:result_schem}.

\begin{figure}[ht]
	\caption{\label{fig:result_schem}Esquema das conexões dos sensores ao Arduino}
	\begin{center}
	    \includegraphics[width=.8\textwidth]{resources/result_schem}
	\end{center}
	\legend{Fonte: Elaborada pelo autor}
\end{figure}

Todos esses equipamentos foram fixados em uma joelheira de material flexível não rígido, como visto na \autoref{fig:result_prototipo}, com o MPU\=/\(6050\) (b) posicionado acima do joelho, e o sensor flexível (a) posicionado na parte de trás. Este último sensor teve de ser posicionado desta forma devido ao seu comprimento de apenas \SI{55.88}{\milli\meter}, já que posicionamento na parte frontal do joelho, como planejado na ~\autoref{sec:metodo_protese}, impediria que a resistência do sensor variasse o suficiente.

\begin{figure}[ht]
	\caption{\label{fig:result_prototipo}Protótipo com o sensor flexível (a) e o MPU-6050 (b) conectados ao Arduino Nano}
    \todo[inline]{Sugiro substituir uma das figuras da joelheira por uma perna usando a joelheira}
	\begin{center}
	    \includegraphics[width=.8\textwidth]{resources/result_prototipo}
	\end{center}
	\legend{Fonte: Elaborada pelo autor}
\end{figure}

Para que fossem feitas a leitura e a classificação dos dados capturados, o Arduino foi conectado via cabo USB em um computador que executava o simulador. Os dados do giroscópio, acelerômetro e resistência do sensor flexível, respectivamente, são enviados continuamente via comunicação serial pelo \textit{software} carregado no Arduino.


% \subsection{\textit{Software} de simulação}\label{sec:result_simulacao}

O sistema de simulação é executado em um computador e foi desenvolvido na linguagem Python 3.7, para facilitar o uso da ferramenta scikit-learn. O programa é composto por diversos componentes que se integram para realizar diferentes atividades: leitura dos dados, através da biblioteca \textit{pyserial}\footnote{\url{https://github.com/pyserial/pyserial}}; gravação dos dados em arquivos; classificação dos dados, utilizando scikit-learn; e a exibição 3D com o uso das bibliotecas \textit{PyOpenGL}\footnote{\url{http://pyopengl.sourceforge.net/}} e \textit{pygame}\footnote{\url{https://www.pygame.org/}}.

%==========================================================================
%
\section{Execução dos experimentos}\label{sec:result_execucao}
%
%==========================================================================

Com o protótipo confeccionado e os \textit{softwares} desenvolvidos, deu-se início aos experimentos com o intuito de responder às questões de pesquisa apresentadas na \autoref{sec:result_planejamento}.

%---------------------------------------------------------------------------
\subsection{Transmissão de dados e ambiente virtual}
%---------------------------------------------------------------------------

O primeiro experimento realizado, visando responder à primeira questão de pesquisa (\ref{qp:simula_movimentos}), foi focado na transmissão de dados dos sensores para o simulador através da comunicação serial enquanto o ambiente virtual replicava os movimentos realizados pelos sensores.

Os dados de orientação, dentre os que são enviados pelo \textit{software} carregado no Arduino, são recebidos pelo simulador e utilizados como ângulos de rotação do modelo da perna virtual, para replicar a orientação do membro do usuário que está utilizando o protótipo. Durante os experimentos, observou-se que foi necessário fazer uma calibragem do MPU-\(6050\) a partir de sua posição vertical, pois os ângulos de rotação precisam ser relativos a uma posição inicial para que a orientação seja precisa.

\begin{figure}[ht]
	\caption{\label{fig:result_simulacao}Visualização da posição da perna do usuário e simulação da prótese}
	\todo[inline]{Adicionar foto da perna ao lado da simulação}
	\begin{center}
	    \includegraphics[width=.8\textwidth]{resources/result_simulacao}
	\end{center}
	\legend{Fonte: Elaborada pelo autor}
\end{figure}

Feito isso, o ambiente virtual foi capaz de replicar a posição da perna do usuário (como pode-se ver na \autoref{fig:result_simulacao}), com apenas uma ressalva: a falta de um magnetômetro no MPU\=/6050 utilizado impede que ele realize rotações em torno do eixo \todo{Conferir se tá certo isso}perpendicular ao solo, fazendo com que a simulação não reconhecesse bem movimentos de virada.

%---------------------------------------------------------------------------
\subsection{Classificação de movimentos}\label{sec:result_classif}
%---------------------------------------------------------------------------

\todo[inline]{Com a utilização de dois datasets, ficou ruim. Tive que usar um dataset só pra caminhada, e outro dataset só pra escada. O da escada foi só subindo com a perna direita e descendo com a esquerda. Lembrar de gerar os gráficos.}
Para tornar possível a previsão dos movimentos, foi decidido que seriam armazenados os valores do acelerômetro e do sensor flexível, ignorando os dados de orientação do giroscópio, que ainda são utilizados para orientar o modelo virtual. Diversos conjuntos de dados foram gravados com diversos tipos de ações diferentes.

Todos os dados foram capturados a partir de um cabo USB de \SI{1.5}{\meter}\todo{Conferir comprimento do cabo} conectado a um \textit{notebook} (com um processador Intel i7\=/7500U, que conta com \textit{clock} de até \SI{3.5}{\giga\hertz}, e \SI{8}{\giga\byte} de RAM) no sistema operacional Manjaro Linux\footnote{\url{http://manjaro.org/}} 18.0.4, estabelecendo comunicação serial com o programa.

Os indivíduos selecionados para a coleta dos dados tinham os membros intactos e vestiram a joelheira com os equipamentos na perna direita e realizavam as ações necessárias para cada etapa do experimento enquanto as transições entre os movimentos eram gravadas em um arquivo.

\todo[inline]{Acrescentar que ao fim de cada geração de dataset, eu rodava o programa que comparava os algoritmos. Lembrar de listar todos os algoritmos comparados}

\subsubsection{Movimentos de caminhada}

O primeiro conjunto de dados gerado foi a partir de dois indivíduos que apenas caminhavam em linha reta. Cada um dos passos de cada perna deveria ser classificado de forma independente. Ou seja, além do estado de repouso (estado 0), foram armazenados o ponto em que a perna esquerda estava para frente (estado 1), e o ponto em que a perna direita estava para frente (estado 2), ilustrados pela \autoref{fig:result_estados}. Ao todo, foram coletadas 140 amostras.

\begin{figure}[ht]
	\caption{\label{fig:result_estados}Demonstração das três ações capturadas para a classificação}
	\begin{center}
	   % \includegraphics[width=\textwidth]{resources/result_estados}
	   \missingfigure[figwidth=\textwidth, figheight=7cm]{Tirar 3 fotos em cada uma das posições para ilustrar as ações no texto (ou só capturar do vídeo de exemplo)}
	\end{center}
	\legend{Fonte: Elaborada pelo autor}
\end{figure}

A partir dos dados coletados dos usuários, verificou-se através de validação cruzada que \textit{Random Forest} seria o algoritmo mais apropriado dentre os disponíveis no scikit-learn, com acurácia de aproximadamente \(82\%\) para os dados combinados de todos os usuários, como pode ser visto no gráfico da \autoref{fig:result_accuracy_rfc}.

\begin{figure}[ht]
	\caption{\label{fig:result_accuracy_rfc}Gráfico de acurácia do algoritmo da Floresta Aleatória para os dados combinados}
% 	\todo[inline]{Tentar gerar um gráfico mais interessante: \url{https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html}}
	\begin{center}
	    \includegraphics[width=\textwidth]{resources/result_accuracy_rfc}
	\end{center}
	\legend{Fonte: Elaborada pelo autor}
\end{figure}

Ao analisar-se os conjuntos de dados de cada indivíduo, sobressaiu-se a Análise de Discriminantes Lineares (LDA), que obteve aproximadamente \(96{,}9\%\) de acurácia, como demonstra a \autoref{fig:result_accuracy_lda}. Devido ao pequeno número de amostras, não foi possível gerar um conjunto de dados genérico que funcionasse para todos os indivíduos a partir da coleta realizada. Portanto, cada usuário teria que fazer a própria calibragem do dispositivo para prever os próprios movimentos.

\begin{figure}[ht]
	\caption{\label{fig:result_accuracy_lda}Gráfico de acurácia da LDA para um conjunto de dados individual}
% 	\todo[inline]{Tentar gerar um gráfico mais interessante: \url{https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html}}
	\begin{center}
	    \includegraphics[width=\textwidth]{resources/result_accuracy_lda}
	\end{center}
	\legend{Fonte: Elaborada pelo autor}
\end{figure}


% \begin{figure}[ht]
% 	\caption{\label{fig:result_accuracy_plot}Gráfico de acurácia do algoritmo CART}
% % 	\todo[inline]{Tentar gerar um gráfico mais interessante: \url{https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html}}
% 	\begin{center}
% 	    \includegraphics[width=\textwidth]{resources/result_accuracy_plot}
% 	\end{center}
% 	\legend{Fonte: Elaborada pelo autor}
% \end{figure}

A simulação animada em 3D, como vista na~\autoref{fig:result_simulacao_2} mostrou-se capaz de exibir o movimento realizado pelos dois sensores em tempo real e, com a classificação dos dados, também a ação realizada na prótese simulada, desde que o conjunto de dados utilizado correspondesse apenas aos dados coletados pelo mesmo usuário que estivesse utilizando o dispositivo.


Além disso, ao longo dos experimentos realizados, notou-se que o sensor flexível ficou cada vez menos preciso, o que tornou a visualização 3D um pouco menos realista, pois o ruído nos dados do sensor tornou-se maior, mas não impediu que os dados fossem classificados e as ações previstas.